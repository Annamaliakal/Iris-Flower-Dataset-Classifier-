{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IrisClassifier(Anna Emmanuel CS5A 13).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5cOTdu3tG3T"
      },
      "source": [
        "# **SC Assignment II**\n",
        "**Iris Flower Dataset Classifier** using Sequential Model API to\n",
        "classify Iris plants into two species Setosa and Versicolor using Iris dataset\n",
        "\n",
        "*Author* :  **Anna Emmanuel  CS5A 13** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swQZ--dgTvSu"
      },
      "source": [
        "# importing packages\n",
        "import tensorflow as tf  \n",
        "from tensorflow import keras  \n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd  \n",
        "import matplotlib.pyplot as plt \n",
        "import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ctIrKzhV6il"
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld7O2bNEWBww",
        "outputId": "78663add-0c14-4128-ddb4-bf4185bc3c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#loading IRIS dataset\n",
        "iris = sns.load_dataset(\"iris\") \n",
        "iris.head(60)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5.2</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>5.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>4.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>5.3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>7.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.4</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>6.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>5.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>6.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1.5</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>6.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.6</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.4</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>6.6</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1.3</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>5.2</td>\n",
              "      <td>2.7</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width     species\n",
              "0            5.1          3.5           1.4          0.2      setosa\n",
              "1            4.9          3.0           1.4          0.2      setosa\n",
              "2            4.7          3.2           1.3          0.2      setosa\n",
              "3            4.6          3.1           1.5          0.2      setosa\n",
              "4            5.0          3.6           1.4          0.2      setosa\n",
              "5            5.4          3.9           1.7          0.4      setosa\n",
              "6            4.6          3.4           1.4          0.3      setosa\n",
              "7            5.0          3.4           1.5          0.2      setosa\n",
              "8            4.4          2.9           1.4          0.2      setosa\n",
              "9            4.9          3.1           1.5          0.1      setosa\n",
              "10           5.4          3.7           1.5          0.2      setosa\n",
              "11           4.8          3.4           1.6          0.2      setosa\n",
              "12           4.8          3.0           1.4          0.1      setosa\n",
              "13           4.3          3.0           1.1          0.1      setosa\n",
              "14           5.8          4.0           1.2          0.2      setosa\n",
              "15           5.7          4.4           1.5          0.4      setosa\n",
              "16           5.4          3.9           1.3          0.4      setosa\n",
              "17           5.1          3.5           1.4          0.3      setosa\n",
              "18           5.7          3.8           1.7          0.3      setosa\n",
              "19           5.1          3.8           1.5          0.3      setosa\n",
              "20           5.4          3.4           1.7          0.2      setosa\n",
              "21           5.1          3.7           1.5          0.4      setosa\n",
              "22           4.6          3.6           1.0          0.2      setosa\n",
              "23           5.1          3.3           1.7          0.5      setosa\n",
              "24           4.8          3.4           1.9          0.2      setosa\n",
              "25           5.0          3.0           1.6          0.2      setosa\n",
              "26           5.0          3.4           1.6          0.4      setosa\n",
              "27           5.2          3.5           1.5          0.2      setosa\n",
              "28           5.2          3.4           1.4          0.2      setosa\n",
              "29           4.7          3.2           1.6          0.2      setosa\n",
              "30           4.8          3.1           1.6          0.2      setosa\n",
              "31           5.4          3.4           1.5          0.4      setosa\n",
              "32           5.2          4.1           1.5          0.1      setosa\n",
              "33           5.5          4.2           1.4          0.2      setosa\n",
              "34           4.9          3.1           1.5          0.2      setosa\n",
              "35           5.0          3.2           1.2          0.2      setosa\n",
              "36           5.5          3.5           1.3          0.2      setosa\n",
              "37           4.9          3.6           1.4          0.1      setosa\n",
              "38           4.4          3.0           1.3          0.2      setosa\n",
              "39           5.1          3.4           1.5          0.2      setosa\n",
              "40           5.0          3.5           1.3          0.3      setosa\n",
              "41           4.5          2.3           1.3          0.3      setosa\n",
              "42           4.4          3.2           1.3          0.2      setosa\n",
              "43           5.0          3.5           1.6          0.6      setosa\n",
              "44           5.1          3.8           1.9          0.4      setosa\n",
              "45           4.8          3.0           1.4          0.3      setosa\n",
              "46           5.1          3.8           1.6          0.2      setosa\n",
              "47           4.6          3.2           1.4          0.2      setosa\n",
              "48           5.3          3.7           1.5          0.2      setosa\n",
              "49           5.0          3.3           1.4          0.2      setosa\n",
              "50           7.0          3.2           4.7          1.4  versicolor\n",
              "51           6.4          3.2           4.5          1.5  versicolor\n",
              "52           6.9          3.1           4.9          1.5  versicolor\n",
              "53           5.5          2.3           4.0          1.3  versicolor\n",
              "54           6.5          2.8           4.6          1.5  versicolor\n",
              "55           5.7          2.8           4.5          1.3  versicolor\n",
              "56           6.3          3.3           4.7          1.6  versicolor\n",
              "57           4.9          2.4           3.3          1.0  versicolor\n",
              "58           6.6          2.9           4.6          1.3  versicolor\n",
              "59           5.2          2.7           3.9          1.4  versicolor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxPTEQusaYKo",
        "outputId": "d418f4cd-c85c-40ff-976d-0d1fc6dc1214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "#Dropping data relating to virginica species\n",
        "iris = iris[iris['species']!='virginica']\n",
        "iris"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>6.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>5.1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.3</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width     species\n",
              "0            5.1          3.5           1.4          0.2      setosa\n",
              "1            4.9          3.0           1.4          0.2      setosa\n",
              "2            4.7          3.2           1.3          0.2      setosa\n",
              "3            4.6          3.1           1.5          0.2      setosa\n",
              "4            5.0          3.6           1.4          0.2      setosa\n",
              "..           ...          ...           ...          ...         ...\n",
              "95           5.7          3.0           4.2          1.2  versicolor\n",
              "96           5.7          2.9           4.2          1.3  versicolor\n",
              "97           6.2          2.9           4.3          1.3  versicolor\n",
              "98           5.1          2.5           3.0          1.1  versicolor\n",
              "99           5.7          2.8           4.1          1.3  versicolor\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGJX0Y630oK6"
      },
      "source": [
        "> We need to convert categorical value i.e. setosa and versicolor into numerical (0 and 1), here we are adding a new column \"Class\" into the DataFrame for the numerical values.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "janVYfLdX2gz",
        "outputId": "8da2aacf-3eec-4bbe-9c82-acaac5482928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "data=pd.DataFrame(iris)\n",
        "labels=[]\n",
        "for i in range(len(data)):\n",
        "  if data['species'][i] =='setosa':      # 0 represents setosa \n",
        "    labels.append(0)\n",
        "  else:\n",
        "    labels.append(1)                     # 1 represents versicolor\n",
        "data['Class']=labels\n",
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>versicolor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>versicolor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>6.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>versicolor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>5.1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>versicolor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.3</td>\n",
              "      <td>versicolor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width     species  Class\n",
              "0            5.1          3.5           1.4          0.2      setosa      0\n",
              "1            4.9          3.0           1.4          0.2      setosa      0\n",
              "2            4.7          3.2           1.3          0.2      setosa      0\n",
              "3            4.6          3.1           1.5          0.2      setosa      0\n",
              "4            5.0          3.6           1.4          0.2      setosa      0\n",
              "..           ...          ...           ...          ...         ...    ...\n",
              "95           5.7          3.0           4.2          1.2  versicolor      1\n",
              "96           5.7          2.9           4.2          1.3  versicolor      1\n",
              "97           6.2          2.9           4.3          1.3  versicolor      1\n",
              "98           5.1          2.5           3.0          1.1  versicolor      1\n",
              "99           5.7          2.8           4.1          1.3  versicolor      1\n",
              "\n",
              "[100 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIWKNFnszcit"
      },
      "source": [
        "**Separating Input and target Variables** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwxlsMYsYFRC"
      },
      "source": [
        "X = data.drop('species', axis=1)\n",
        "X= X.drop('Class',axis=1)\n",
        "Y = data['Class'] "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBonEZOJzuIz"
      },
      "source": [
        "**Splitting into Train and Test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c2MKlOZzrB8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9IiFTqAGKv5"
      },
      "source": [
        "**Defining and Building the model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVi3xrDxdcDG"
      },
      "source": [
        "#Defining the model\n",
        "model = Sequential()\n",
        "\n",
        "#Building the model\n",
        "model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYEJliLfjKoV",
        "outputId": "e72b4b4d-aef3-4a09-f888-f085237ac141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 32)                160       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 833\n",
            "Trainable params: 833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTEnx_4CdhTe"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "#Compiling the model\n",
        "optimizer = RMSprop(0.01)  #learning rate = 0.01\n",
        "model.compile(loss='binary_crossentropy', optimizer= optimizer , metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnApxdbv1Ib1"
      },
      "source": [
        "**Training the model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHPKEDY0fDBw",
        "outputId": "4480be1e-799f-4cce-8378-f6cfccb17acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit(X_train, Y_train,validation_split=0.2,epochs=200, batch_size=10, verbose = 1) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6112 - accuracy: 0.7031 - val_loss: 0.4828 - val_accuracy: 1.0000\n",
            "Epoch 2/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8750 - val_loss: 0.3404 - val_accuracy: 0.6875\n",
            "Epoch 3/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1613 - accuracy: 0.9219 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
            "Epoch 4/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
            "Epoch 5/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.4916e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0232e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.7248e-04 - accuracy: 1.0000 - val_loss: 2.2239e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6099e-04 - accuracy: 1.0000 - val_loss: 1.3436e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.5690e-04 - accuracy: 1.0000 - val_loss: 1.1316e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.0738e-04 - accuracy: 1.0000 - val_loss: 3.9241e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 9.9291e-05 - accuracy: 1.0000 - val_loss: 2.2561e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.5656e-04 - accuracy: 1.0000 - val_loss: 9.7117e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 7.7343e-05 - accuracy: 1.0000 - val_loss: 1.2875e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 6.2092e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 7.1898e-04 - accuracy: 1.0000 - val_loss: 8.2080e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.6288e-04 - accuracy: 1.0000 - val_loss: 3.8287e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 8.7044e-05 - accuracy: 1.0000 - val_loss: 2.4112e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.9059e-05 - accuracy: 1.0000 - val_loss: 1.6060e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.2113e-05 - accuracy: 1.0000 - val_loss: 1.1822e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2198e-05 - accuracy: 1.0000 - val_loss: 9.0151e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.5353e-05 - accuracy: 1.0000 - val_loss: 7.3155e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.1171e-05 - accuracy: 1.0000 - val_loss: 5.7379e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.7042e-05 - accuracy: 1.0000 - val_loss: 4.6878e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.4132e-05 - accuracy: 1.0000 - val_loss: 3.8760e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.1920e-05 - accuracy: 1.0000 - val_loss: 3.0553e-06 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 9.6178e-06 - accuracy: 1.0000 - val_loss: 2.3150e-06 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 7.8920e-06 - accuracy: 1.0000 - val_loss: 2.4421e-06 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 6.3226e-06 - accuracy: 1.0000 - val_loss: 1.0427e-06 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.5590e-06 - accuracy: 1.0000 - val_loss: 6.9264e-07 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.7029e-06 - accuracy: 1.0000 - val_loss: 4.9531e-07 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.3250e-06 - accuracy: 1.0000 - val_loss: 2.9814e-07 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.2832e-06 - accuracy: 1.0000 - val_loss: 2.0619e-07 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 9.7505e-07 - accuracy: 1.0000 - val_loss: 1.3945e-07 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 8.8670e-07 - accuracy: 1.0000 - val_loss: 8.5925e-08 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3048e-06 - accuracy: 1.0000 - val_loss: 1.4682e-07 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 8.7959e-07 - accuracy: 1.0000 - val_loss: 3.1045e-08 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2047e-07 - accuracy: 1.0000 - val_loss: 1.1369e-08 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 9.2934e-08 - accuracy: 1.0000 - val_loss: 8.8587e-09 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 7.3874e-08 - accuracy: 1.0000 - val_loss: 6.8532e-09 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 6.3187e-08 - accuracy: 1.0000 - val_loss: 5.1513e-09 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.5981e-08 - accuracy: 1.0000 - val_loss: 3.4788e-09 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6064e-08 - accuracy: 1.0000 - val_loss: 2.9548e-08 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 8.8494e-04 - accuracy: 1.0000 - val_loss: 1.8975e-05 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.7002e-05 - accuracy: 1.0000 - val_loss: 1.8500e-06 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 8.5550e-06 - accuracy: 1.0000 - val_loss: 1.2261e-06 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 6.0732e-06 - accuracy: 1.0000 - val_loss: 2.9712e-07 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.8836e-06 - accuracy: 1.0000 - val_loss: 2.4566e-07 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.6082e-06 - accuracy: 1.0000 - val_loss: 1.8978e-07 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.2941e-06 - accuracy: 1.0000 - val_loss: 7.6684e-08 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 6.0788e-07 - accuracy: 1.0000 - val_loss: 6.2003e-08 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 5.0759e-07 - accuracy: 1.0000 - val_loss: 4.6714e-08 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.9997e-07 - accuracy: 1.0000 - val_loss: 3.6539e-08 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2390e-07 - accuracy: 1.0000 - val_loss: 2.5270e-08 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.3664e-07 - accuracy: 1.0000 - val_loss: 1.8579e-08 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.8065e-07 - accuracy: 1.0000 - val_loss: 1.2568e-08 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.2609e-07 - accuracy: 1.0000 - val_loss: 9.0631e-09 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 9.2792e-08 - accuracy: 1.0000 - val_loss: 6.3553e-09 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 6.6219e-08 - accuracy: 1.0000 - val_loss: 4.5872e-09 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.8282e-08 - accuracy: 1.0000 - val_loss: 3.4061e-09 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5722e-08 - accuracy: 1.0000 - val_loss: 2.5746e-09 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.6469e-08 - accuracy: 1.0000 - val_loss: 1.8836e-09 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.9063e-08 - accuracy: 1.0000 - val_loss: 1.5181e-09 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.4408e-08 - accuracy: 1.0000 - val_loss: 1.2922e-09 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.2186e-08 - accuracy: 1.0000 - val_loss: 1.1178e-09 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.0475e-08 - accuracy: 1.0000 - val_loss: 9.7247e-10 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 9.0783e-09 - accuracy: 1.0000 - val_loss: 8.2831e-10 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 7.9928e-09 - accuracy: 1.0000 - val_loss: 7.0858e-10 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 7.0744e-09 - accuracy: 1.0000 - val_loss: 5.6569e-10 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 7.4106e-09 - accuracy: 1.0000 - val_loss: 3.9984e-10 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.1658e-09 - accuracy: 1.0000 - val_loss: 3.2910e-10 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1281e-09 - accuracy: 1.0000 - val_loss: 2.6062e-10 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4832e-09 - accuracy: 1.0000 - val_loss: 2.1427e-10 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.0814e-09 - accuracy: 1.0000 - val_loss: 1.7693e-10 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.6926e-09 - accuracy: 1.0000 - val_loss: 3.8048e-10 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.6946e-09 - accuracy: 1.0000 - val_loss: 1.8089e-10 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.2359e-08 - accuracy: 1.0000 - val_loss: 1.0581e-07 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.3806e-07 - accuracy: 1.0000 - val_loss: 2.6058e-04 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.0668e-06 - accuracy: 1.0000 - val_loss: 1.4321e-10 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 9.1554e-09 - accuracy: 1.0000 - val_loss: 1.2120e-10 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 6.1006e-09 - accuracy: 1.0000 - val_loss: 1.0782e-10 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 5.3146e-09 - accuracy: 1.0000 - val_loss: 9.5584e-11 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.8770e-09 - accuracy: 1.0000 - val_loss: 6.6236e-11 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4565e-09 - accuracy: 1.0000 - val_loss: 5.9211e-11 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.1137e-09 - accuracy: 1.0000 - val_loss: 5.1723e-11 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.7365e-09 - accuracy: 1.0000 - val_loss: 4.2601e-11 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.3575e-09 - accuracy: 1.0000 - val_loss: 3.1631e-11 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.7350e-09 - accuracy: 1.0000 - val_loss: 2.6344e-11 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.4496e-09 - accuracy: 1.0000 - val_loss: 2.0736e-11 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.1816e-09 - accuracy: 1.0000 - val_loss: 1.5615e-11 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 8.7842e-10 - accuracy: 1.0000 - val_loss: 1.0432e-11 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 6.2292e-10 - accuracy: 1.0000 - val_loss: 1.0445e-11 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 6.2561e-10 - accuracy: 1.0000 - val_loss: 3.9006e-12 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.8872e-10 - accuracy: 1.0000 - val_loss: 3.8855e-12 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.8944e-10 - accuracy: 1.0000 - val_loss: 3.8500e-12 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.9237e-10 - accuracy: 1.0000 - val_loss: 3.8369e-12 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.9373e-10 - accuracy: 1.0000 - val_loss: 3.8254e-12 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.9475e-10 - accuracy: 1.0000 - val_loss: 3.8151e-12 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.9699e-10 - accuracy: 1.0000 - val_loss: 3.8067e-12 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.0107e-10 - accuracy: 1.0000 - val_loss: 3.8003e-12 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.0067e-10 - accuracy: 1.0000 - val_loss: 3.7941e-12 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.0683e-10 - accuracy: 1.0000 - val_loss: 3.7950e-12 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.1228e-10 - accuracy: 1.0000 - val_loss: 3.7977e-12 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.1225e-10 - accuracy: 1.0000 - val_loss: 3.8022e-12 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.1764e-10 - accuracy: 1.0000 - val_loss: 3.8081e-12 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.2082e-10 - accuracy: 1.0000 - val_loss: 3.8153e-12 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.2048e-10 - accuracy: 1.0000 - val_loss: 3.8220e-12 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.2578e-10 - accuracy: 1.0000 - val_loss: 3.8261e-12 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.2990e-10 - accuracy: 1.0000 - val_loss: 3.8309e-12 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.3229e-10 - accuracy: 1.0000 - val_loss: 3.8364e-12 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.3229e-10 - accuracy: 1.0000 - val_loss: 3.8528e-12 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.3760e-10 - accuracy: 1.0000 - val_loss: 3.8603e-12 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.3970e-10 - accuracy: 1.0000 - val_loss: 3.8809e-12 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.4517e-10 - accuracy: 1.0000 - val_loss: 3.8900e-12 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.4940e-10 - accuracy: 1.0000 - val_loss: 3.8993e-12 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.5146e-10 - accuracy: 1.0000 - val_loss: 3.9090e-12 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.5148e-10 - accuracy: 1.0000 - val_loss: 3.9191e-12 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.5353e-10 - accuracy: 1.0000 - val_loss: 3.9293e-12 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.5742e-10 - accuracy: 1.0000 - val_loss: 3.9400e-12 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.5954e-10 - accuracy: 1.0000 - val_loss: 3.9508e-12 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.5972e-10 - accuracy: 1.0000 - val_loss: 3.9618e-12 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.6168e-10 - accuracy: 1.0000 - val_loss: 3.9730e-12 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.6564e-10 - accuracy: 1.0000 - val_loss: 3.9844e-12 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.6769e-10 - accuracy: 1.0000 - val_loss: 3.9960e-12 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.6952e-10 - accuracy: 1.0000 - val_loss: 4.0079e-12 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.7010e-10 - accuracy: 1.0000 - val_loss: 4.0198e-12 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.7201e-10 - accuracy: 1.0000 - val_loss: 4.0318e-12 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.7577e-10 - accuracy: 1.0000 - val_loss: 4.0440e-12 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.7594e-10 - accuracy: 1.0000 - val_loss: 4.0565e-12 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.7980e-10 - accuracy: 1.0000 - val_loss: 4.0689e-12 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.7972e-10 - accuracy: 1.0000 - val_loss: 4.0816e-12 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.8171e-10 - accuracy: 1.0000 - val_loss: 4.0943e-12 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.8384e-10 - accuracy: 1.0000 - val_loss: 4.1070e-12 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.8716e-10 - accuracy: 1.0000 - val_loss: 4.1197e-12 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.8760e-10 - accuracy: 1.0000 - val_loss: 4.1326e-12 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 2.9138e-10 - accuracy: 1.0000 - val_loss: 4.1455e-12 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.9134e-10 - accuracy: 1.0000 - val_loss: 4.1586e-12 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.9499e-10 - accuracy: 1.0000 - val_loss: 4.1715e-12 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.9702e-10 - accuracy: 1.0000 - val_loss: 4.1846e-12 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.9698e-10 - accuracy: 1.0000 - val_loss: 4.1977e-12 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.9893e-10 - accuracy: 1.0000 - val_loss: 4.2111e-12 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.0073e-10 - accuracy: 1.0000 - val_loss: 4.2242e-12 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.0433e-10 - accuracy: 1.0000 - val_loss: 4.2375e-12 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.0627e-10 - accuracy: 1.0000 - val_loss: 4.2507e-12 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.0631e-10 - accuracy: 1.0000 - val_loss: 4.2641e-12 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.0811e-10 - accuracy: 1.0000 - val_loss: 4.2773e-12 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 4.2906e-12 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.1170e-10 - accuracy: 1.0000 - val_loss: 4.3039e-12 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.1379e-10 - accuracy: 1.0000 - val_loss: 4.3172e-12 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.1692e-10 - accuracy: 1.0000 - val_loss: 4.3305e-12 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.1747e-10 - accuracy: 1.0000 - val_loss: 4.3439e-12 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.1900e-10 - accuracy: 1.0000 - val_loss: 4.3573e-12 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2070e-10 - accuracy: 1.0000 - val_loss: 4.3707e-12 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2423e-10 - accuracy: 1.0000 - val_loss: 4.3841e-12 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2434e-10 - accuracy: 1.0000 - val_loss: 4.3974e-12 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.2748e-10 - accuracy: 1.0000 - val_loss: 4.4108e-12 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2922e-10 - accuracy: 1.0000 - val_loss: 4.4243e-12 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3109e-10 - accuracy: 1.0000 - val_loss: 4.4376e-12 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.3277e-10 - accuracy: 1.0000 - val_loss: 4.4512e-12 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3460e-10 - accuracy: 1.0000 - val_loss: 4.4646e-12 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.3476e-10 - accuracy: 1.0000 - val_loss: 4.4780e-12 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3657e-10 - accuracy: 1.0000 - val_loss: 4.4913e-12 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.3837e-10 - accuracy: 1.0000 - val_loss: 4.5046e-12 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.3979e-10 - accuracy: 1.0000 - val_loss: 4.5179e-12 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.4141e-10 - accuracy: 1.0000 - val_loss: 4.5312e-12 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4473e-10 - accuracy: 1.0000 - val_loss: 4.5444e-12 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4475e-10 - accuracy: 1.0000 - val_loss: 4.5580e-12 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4660e-10 - accuracy: 1.0000 - val_loss: 4.5713e-12 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4945e-10 - accuracy: 1.0000 - val_loss: 4.5845e-12 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.4979e-10 - accuracy: 1.0000 - val_loss: 4.5977e-12 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5170e-10 - accuracy: 1.0000 - val_loss: 4.6109e-12 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5468e-10 - accuracy: 1.0000 - val_loss: 4.6241e-12 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5632e-10 - accuracy: 1.0000 - val_loss: 4.6373e-12 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5796e-10 - accuracy: 1.0000 - val_loss: 4.6504e-12 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.5804e-10 - accuracy: 1.0000 - val_loss: 4.6635e-12 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5959e-10 - accuracy: 1.0000 - val_loss: 4.6766e-12 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6127e-10 - accuracy: 1.0000 - val_loss: 4.6896e-12 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6288e-10 - accuracy: 1.0000 - val_loss: 4.7028e-12 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6452e-10 - accuracy: 1.0000 - val_loss: 4.7158e-12 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6601e-10 - accuracy: 1.0000 - val_loss: 4.7288e-12 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.6772e-10 - accuracy: 1.0000 - val_loss: 4.7418e-12 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7077e-10 - accuracy: 1.0000 - val_loss: 4.7547e-12 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7215e-10 - accuracy: 1.0000 - val_loss: 4.7677e-12 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7237e-10 - accuracy: 1.0000 - val_loss: 4.7806e-12 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7513e-10 - accuracy: 1.0000 - val_loss: 4.7935e-12 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7698e-10 - accuracy: 1.0000 - val_loss: 4.8064e-12 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7832e-10 - accuracy: 1.0000 - val_loss: 4.8192e-12 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7996e-10 - accuracy: 1.0000 - val_loss: 4.8322e-12 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.8138e-10 - accuracy: 1.0000 - val_loss: 4.8450e-12 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8317e-10 - accuracy: 1.0000 - val_loss: 4.8577e-12 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8452e-10 - accuracy: 1.0000 - val_loss: 4.8705e-12 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8491e-10 - accuracy: 1.0000 - val_loss: 4.8833e-12 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8641e-10 - accuracy: 1.0000 - val_loss: 4.8959e-12 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8926e-10 - accuracy: 1.0000 - val_loss: 4.9086e-12 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8934e-10 - accuracy: 1.0000 - val_loss: 4.9212e-12 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9230e-10 - accuracy: 1.0000 - val_loss: 4.9340e-12 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp3v4GEe1fDe"
      },
      "source": [
        "**Model Evaluation** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbXcjoIwfIVA",
        "outputId": "31ee4dd1-7db2-4f80-f236-833479863a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0878e-12 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.087831213997248e-12, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F09EW_5z1-Si"
      },
      "source": [
        "**Model Accuracy** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjpNGTrm19cT",
        "outputId": "4d725e0f-fa95-473f-8947-78e4e7893c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEUf7Ite2lEa"
      },
      "source": [
        "**Model Loss**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McahmIre2kUD",
        "outputId": "b3793e5b-ce56-4c7a-cb45-ec00ebb227db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFS-hhJl8van"
      },
      "source": [
        "**Prediction** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qkqunOB9U8r"
      },
      "source": [
        "> Since we have used one output neuron while defining the model and loss as binary_crossentropy while compiling the model, we will get single probability value.\n",
        "\n",
        "> As our predictions are single probability value. We can use a threshold value to get the actual labels. Here we have taken a threshold of 0.5.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vSSuQAMfkBA"
      },
      "source": [
        "pred=model.predict(X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMnkUGbUgdVQ"
      },
      "source": [
        "prediction = []\n",
        "for value in pred:\n",
        "  if value <= 0.5:            # threshold of 0.5\n",
        "    prediction.append(0)      # 0 implies 'setosa'\n",
        "  else:\n",
        "    prediction.append(1)      # 1 implies 'versicolor'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzwg1KHmge1R"
      },
      "source": [
        "Y_pred=[]\n",
        "for x in prediction:\n",
        "  if x==0:\n",
        "    Y_pred.append('setosa')\n",
        "  else:\n",
        "    Y_pred.append('versicolor')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bbQRuUe-jMD"
      },
      "source": [
        "**Prediction Results** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87YXa8Wwh295",
        "outputId": "337b7051-e575-4181-c8df-40a1714b34a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        }
      },
      "source": [
        "result=pd.DataFrame(X_test)\n",
        "result['target_species']=Y_pred\n",
        "result"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>target_species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>6.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>5.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.8</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>5.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>6.1</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.2</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>5.5</td>\n",
              "      <td>2.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.2</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>6.8</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width target_species\n",
              "83           6.0          2.7           5.1          1.6     versicolor\n",
              "53           5.5          2.3           4.0          1.3     versicolor\n",
              "70           5.9          3.2           4.8          1.8     versicolor\n",
              "45           4.8          3.0           1.4          0.3         setosa\n",
              "44           5.1          3.8           1.9          0.4         setosa\n",
              "39           5.1          3.4           1.5          0.2         setosa\n",
              "22           4.6          3.6           1.0          0.2         setosa\n",
              "80           5.5          2.4           3.8          1.1     versicolor\n",
              "10           5.4          3.7           1.5          0.2         setosa\n",
              "0            5.1          3.5           1.4          0.2         setosa\n",
              "18           5.7          3.8           1.7          0.3         setosa\n",
              "30           4.8          3.1           1.6          0.2         setosa\n",
              "73           6.1          2.8           4.7          1.2     versicolor\n",
              "33           5.5          4.2           1.4          0.2         setosa\n",
              "90           5.5          2.6           4.4          1.2     versicolor\n",
              "4            5.0          3.6           1.4          0.2         setosa\n",
              "76           6.8          2.8           4.8          1.4     versicolor\n",
              "77           6.7          3.0           5.0          1.7     versicolor\n",
              "12           4.8          3.0           1.4          0.1         setosa\n",
              "31           5.4          3.4           1.5          0.4         setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBDyQta3h30r"
      },
      "source": [
        "Y_test=['setosa' if x==0 else 'versicolor' for x in Y_test] #Converting back to categorical values\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cf_matrix = confusion_matrix(Y_test, Y_pred)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk9wGbGmsHHq",
        "outputId": "ee646cfe-9291-4429-d254-482630dc09c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "sns.heatmap(cf_matrix, annot=True,cmap='Blues')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15dd0bb518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NhyubJiHNeB",
        "outputId": "69ad19d5-a794-4b80-a0c5-715d6d020147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%',cmap='binary')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15dd11d5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WCLN6nQRA2n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}